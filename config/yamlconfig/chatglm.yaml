chatglm-6b:
  auto_merge_lora_single: true
  auto_quantize: false
  enable: false
  max_batch_size: 1
  model_config:
    do_lower_case: null
    lora: {}
    model_name_or_path: /data/nlp/pre_models/torch/chatglm/chatglm-6b
    model_type: chatglm
    use_fast_tokenizer: false
  ntk_scale: 1
  work_mode: deepspeed
  workers:
  - device_id:
    - 0
chatglm-6b-int4:
  auto_merge_lora_single: true
  auto_quantize: false
  enable: false
  max_batch_size: 1
  model_config:
    do_lower_case: null
    lora: {}
    model_name_or_path: /data/nlp/pre_models/torch/chatglm/chatglm-6b-int4
    model_type: chatglm
    use_fast_tokenizer: false
  ntk_scale: 1
  work_mode: deepspeed
  workers:
  - device_id:
    - 0
